<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - filtered.info - /home/seame/tensorrt-8.6.1.6/include/NvInferRuntimeBase.h</title>
  <link rel="stylesheet" type="text/css" href="../../../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../../../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../../../index.html">top level</a> - <a href="index.html">home/seame/tensorrt-8.6.1.6/include</a> - NvInferRuntimeBase.h<span style="font-size: 80%;"> (source / <a href="NvInferRuntimeBase.h.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">filtered.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">0</td>
            <td class="headerCovTableEntry">1</td>
            <td class="headerCovTableEntryLo">0.0 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2025-07-08 20:40:10</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">0</td>
            <td class="headerCovTableEntry">2</td>
            <td class="headerCovTableEntryLo">0.0 %</td>
          </tr>
          <tr><td><img src="../../../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : /*</a>
<a name="2"><span class="lineNum">       2 </span>            :  * SPDX-FileCopyrightText: Copyright (c) 1993-2023 NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved.</a>
<a name="3"><span class="lineNum">       3 </span>            :  * SPDX-License-Identifier: LicenseRef-NvidiaProprietary</a>
<a name="4"><span class="lineNum">       4 </span>            :  *</a>
<a name="5"><span class="lineNum">       5 </span>            :  * NVIDIA CORPORATION, its affiliates and licensors retain all intellectual</a>
<a name="6"><span class="lineNum">       6 </span>            :  * property and proprietary rights in and to this material, related</a>
<a name="7"><span class="lineNum">       7 </span>            :  * documentation and any modifications thereto. Any use, reproduction,</a>
<a name="8"><span class="lineNum">       8 </span>            :  * disclosure or distribution of this material and related documentation</a>
<a name="9"><span class="lineNum">       9 </span>            :  * without an express license agreement from NVIDIA CORPORATION or</a>
<a name="10"><span class="lineNum">      10 </span>            :  * its affiliates is strictly prohibited.</a>
<a name="11"><span class="lineNum">      11 </span>            :  */</a>
<a name="12"><span class="lineNum">      12 </span>            : </a>
<a name="13"><span class="lineNum">      13 </span>            : #ifndef NV_INFER_RUNTIME_BASE_H</a>
<a name="14"><span class="lineNum">      14 </span>            : #define NV_INFER_RUNTIME_BASE_H</a>
<a name="15"><span class="lineNum">      15 </span>            : </a>
<a name="16"><span class="lineNum">      16 </span>            : #include &quot;NvInferVersion.h&quot;</a>
<a name="17"><span class="lineNum">      17 </span>            : #include &lt;cstddef&gt;</a>
<a name="18"><span class="lineNum">      18 </span>            : #include &lt;cstdint&gt;</a>
<a name="19"><span class="lineNum">      19 </span>            : #include &lt;cuda_runtime_api.h&gt;</a>
<a name="20"><span class="lineNum">      20 </span>            : </a>
<a name="21"><span class="lineNum">      21 </span>            : // Items that are marked as deprecated will be removed in a future release.</a>
<a name="22"><span class="lineNum">      22 </span>            : #if __cplusplus &gt;= 201402L</a>
<a name="23"><span class="lineNum">      23 </span>            : #define TRT_DEPRECATED [[deprecated]]</a>
<a name="24"><span class="lineNum">      24 </span>            : #if __GNUC__ &lt; 6</a>
<a name="25"><span class="lineNum">      25 </span>            : #define TRT_DEPRECATED_ENUM</a>
<a name="26"><span class="lineNum">      26 </span>            : #else</a>
<a name="27"><span class="lineNum">      27 </span>            : #define TRT_DEPRECATED_ENUM TRT_DEPRECATED</a>
<a name="28"><span class="lineNum">      28 </span>            : #endif</a>
<a name="29"><span class="lineNum">      29 </span>            : #ifdef _MSC_VER</a>
<a name="30"><span class="lineNum">      30 </span>            : #define TRT_DEPRECATED_API __declspec(dllexport)</a>
<a name="31"><span class="lineNum">      31 </span>            : #else</a>
<a name="32"><span class="lineNum">      32 </span>            : #define TRT_DEPRECATED_API [[deprecated]] __attribute__((visibility(&quot;default&quot;)))</a>
<a name="33"><span class="lineNum">      33 </span>            : #endif</a>
<a name="34"><span class="lineNum">      34 </span>            : #else</a>
<a name="35"><span class="lineNum">      35 </span>            : #ifdef _MSC_VER</a>
<a name="36"><span class="lineNum">      36 </span>            : #define TRT_DEPRECATED</a>
<a name="37"><span class="lineNum">      37 </span>            : #define TRT_DEPRECATED_ENUM</a>
<a name="38"><span class="lineNum">      38 </span>            : #define TRT_DEPRECATED_API __declspec(dllexport)</a>
<a name="39"><span class="lineNum">      39 </span>            : #else</a>
<a name="40"><span class="lineNum">      40 </span>            : #define TRT_DEPRECATED __attribute__((deprecated))</a>
<a name="41"><span class="lineNum">      41 </span>            : #define TRT_DEPRECATED_ENUM</a>
<a name="42"><span class="lineNum">      42 </span>            : #define TRT_DEPRECATED_API __attribute__((deprecated, visibility(&quot;default&quot;)))</a>
<a name="43"><span class="lineNum">      43 </span>            : #endif</a>
<a name="44"><span class="lineNum">      44 </span>            : #endif</a>
<a name="45"><span class="lineNum">      45 </span>            : </a>
<a name="46"><span class="lineNum">      46 </span>            : // Defines which symbols are exported</a>
<a name="47"><span class="lineNum">      47 </span>            : #ifdef TENSORRT_BUILD_LIB</a>
<a name="48"><span class="lineNum">      48 </span>            : #ifdef _MSC_VER</a>
<a name="49"><span class="lineNum">      49 </span>            : #define TENSORRTAPI __declspec(dllexport)</a>
<a name="50"><span class="lineNum">      50 </span>            : #else</a>
<a name="51"><span class="lineNum">      51 </span>            : #define TENSORRTAPI __attribute__((visibility(&quot;default&quot;)))</a>
<a name="52"><span class="lineNum">      52 </span>            : #endif</a>
<a name="53"><span class="lineNum">      53 </span>            : #else</a>
<a name="54"><span class="lineNum">      54 </span>            : #define TENSORRTAPI</a>
<a name="55"><span class="lineNum">      55 </span>            : #endif</a>
<a name="56"><span class="lineNum">      56 </span>            : #define TRTNOEXCEPT</a>
<a name="57"><span class="lineNum">      57 </span>            : //!</a>
<a name="58"><span class="lineNum">      58 </span>            : //! \file NvInferRuntimeBase.h</a>
<a name="59"><span class="lineNum">      59 </span>            : //!</a>
<a name="60"><span class="lineNum">      60 </span>            : //! This file contains common definitions, data structures and interfaces shared between the standard and safe runtime.</a>
<a name="61"><span class="lineNum">      61 </span>            : //!</a>
<a name="62"><span class="lineNum">      62 </span>            : //! \warning Do not directly include this file. Instead include either NvInferRuntime.h (for the standard runtime) or</a>
<a name="63"><span class="lineNum">      63 </span>            : //! NvInferSafeRuntime.h (for the safety runtime).</a>
<a name="64"><span class="lineNum">      64 </span>            : //!</a>
<a name="65"><span class="lineNum">      65 </span>            : </a>
<a name="66"><span class="lineNum">      66 </span>            : // forward declare some CUDA types to avoid an include dependency</a>
<a name="67"><span class="lineNum">      67 </span>            : </a>
<a name="68"><span class="lineNum">      68 </span>            : extern &quot;C&quot;</a>
<a name="69"><span class="lineNum">      69 </span>            : {</a>
<a name="70"><span class="lineNum">      70 </span>            :     //! Forward declaration of cublasContext to use in other interfaces</a>
<a name="71"><span class="lineNum">      71 </span>            :     struct cublasContext;</a>
<a name="72"><span class="lineNum">      72 </span>            :     //! Forward declaration of cudnnContext to use in other interfaces</a>
<a name="73"><span class="lineNum">      73 </span>            :     struct cudnnContext;</a>
<a name="74"><span class="lineNum">      74 </span>            : }</a>
<a name="75"><span class="lineNum">      75 </span>            : </a>
<a name="76"><span class="lineNum">      76 </span>            : #define NV_TENSORRT_VERSION nvinfer1::kNV_TENSORRT_VERSION_IMPL</a>
<a name="77"><span class="lineNum">      77 </span>            : //!</a>
<a name="78"><span class="lineNum">      78 </span>            : //! \namespace nvinfer1</a>
<a name="79"><span class="lineNum">      79 </span>            : //!</a>
<a name="80"><span class="lineNum">      80 </span>            : //! \brief The TensorRT API version 1 namespace.</a>
<a name="81"><span class="lineNum">      81 </span>            : //!</a>
<a name="82"><span class="lineNum">      82 </span>            : namespace nvinfer1</a>
<a name="83"><span class="lineNum">      83 </span>            : {</a>
<a name="84"><span class="lineNum">      84 </span>            : </a>
<a name="85"><span class="lineNum">      85 </span>            : static constexpr int32_t kNV_TENSORRT_VERSION_IMPL</a>
<a name="86"><span class="lineNum">      86 </span>            :     = (NV_TENSORRT_MAJOR * 1000) + (NV_TENSORRT_MINOR * 100) + NV_TENSORRT_PATCH; // major, minor, patch</a>
<a name="87"><span class="lineNum">      87 </span>            : </a>
<a name="88"><span class="lineNum">      88 </span>            : //! char_t is the type used by TensorRT to represent all valid characters.</a>
<a name="89"><span class="lineNum">      89 </span>            : using char_t = char;</a>
<a name="90"><span class="lineNum">      90 </span>            : </a>
<a name="91"><span class="lineNum">      91 </span>            : //! AsciiChar is the type used by TensorRT to represent valid ASCII characters.</a>
<a name="92"><span class="lineNum">      92 </span>            : //! This type is used by IPluginV2, PluginField, IPluginCreator, IPluginRegistry, and</a>
<a name="93"><span class="lineNum">      93 </span>            : //! ILogger due to their use in automotive safety context.</a>
<a name="94"><span class="lineNum">      94 </span>            : using AsciiChar = char_t;</a>
<a name="95"><span class="lineNum">      95 </span>            : </a>
<a name="96"><span class="lineNum">      96 </span>            : //! Forward declare IErrorRecorder for use in other interfaces.</a>
<a name="97"><span class="lineNum">      97 </span>            : class IErrorRecorder;</a>
<a name="98"><span class="lineNum">      98 </span>            : //! Forward declare IGpuAllocator for use in other interfaces.</a>
<a name="99"><span class="lineNum">      99 </span>            : class IGpuAllocator;</a>
<a name="100"><span class="lineNum">     100 </span>            : </a>
<a name="101"><span class="lineNum">     101 </span>            : namespace impl</a>
<a name="102"><span class="lineNum">     102 </span>            : {</a>
<a name="103"><span class="lineNum">     103 </span>            : //! Declaration of EnumMaxImpl struct to store maximum number of elements in an enumeration type.</a>
<a name="104"><span class="lineNum">     104 </span>            : template &lt;typename T&gt;</a>
<a name="105"><span class="lineNum">     105 </span>            : struct EnumMaxImpl;</a>
<a name="106"><span class="lineNum">     106 </span>            : } // namespace impl</a>
<a name="107"><span class="lineNum">     107 </span>            : </a>
<a name="108"><span class="lineNum">     108 </span>            : //! Maximum number of elements in an enumeration type.</a>
<a name="109"><span class="lineNum">     109 </span>            : template &lt;typename T&gt;</a>
<a name="110"><span class="lineNum">     110 </span>            : constexpr int32_t EnumMax() noexcept</a>
<a name="111"><span class="lineNum">     111 </span>            : {</a>
<a name="112"><span class="lineNum">     112 </span>            :     return impl::EnumMaxImpl&lt;T&gt;::kVALUE;</a>
<a name="113"><span class="lineNum">     113 </span>            : }</a>
<a name="114"><span class="lineNum">     114 </span>            : </a>
<a name="115"><span class="lineNum">     115 </span>            : //!</a>
<a name="116"><span class="lineNum">     116 </span>            : //! \enum DataType</a>
<a name="117"><span class="lineNum">     117 </span>            : //! \brief The type of weights and tensors.</a>
<a name="118"><span class="lineNum">     118 </span>            : //!</a>
<a name="119"><span class="lineNum">     119 </span>            : enum class DataType : int32_t</a>
<a name="120"><span class="lineNum">     120 </span>            : {</a>
<a name="121"><span class="lineNum">     121 </span>            :     //! 32-bit floating point format.</a>
<a name="122"><span class="lineNum">     122 </span>            :     kFLOAT = 0,</a>
<a name="123"><span class="lineNum">     123 </span>            : </a>
<a name="124"><span class="lineNum">     124 </span>            :     //! IEEE 16-bit floating-point format.</a>
<a name="125"><span class="lineNum">     125 </span>            :     kHALF = 1,</a>
<a name="126"><span class="lineNum">     126 </span>            : </a>
<a name="127"><span class="lineNum">     127 </span>            :     //! Signed 8-bit integer representing a quantized floating-point value.</a>
<a name="128"><span class="lineNum">     128 </span>            :     kINT8 = 2,</a>
<a name="129"><span class="lineNum">     129 </span>            : </a>
<a name="130"><span class="lineNum">     130 </span>            :     //! Signed 32-bit integer format.</a>
<a name="131"><span class="lineNum">     131 </span>            :     kINT32 = 3,</a>
<a name="132"><span class="lineNum">     132 </span>            : </a>
<a name="133"><span class="lineNum">     133 </span>            :     //! 8-bit boolean. 0 = false, 1 = true, other values undefined.</a>
<a name="134"><span class="lineNum">     134 </span>            :     kBOOL = 4,</a>
<a name="135"><span class="lineNum">     135 </span>            : </a>
<a name="136"><span class="lineNum">     136 </span>            :     //! Unsigned 8-bit integer format.</a>
<a name="137"><span class="lineNum">     137 </span>            :     //! Cannot be used to represent quantized floating-point values.</a>
<a name="138"><span class="lineNum">     138 </span>            :     //! Use the IdentityLayer to convert kUINT8 network-level inputs to {kFLOAT, kHALF} prior</a>
<a name="139"><span class="lineNum">     139 </span>            :     //! to use with other TensorRT layers, or to convert intermediate output</a>
<a name="140"><span class="lineNum">     140 </span>            :     //! before kUINT8 network-level outputs from {kFLOAT, kHALF} to kUINT8.</a>
<a name="141"><span class="lineNum">     141 </span>            :     //! kUINT8 conversions are only supported for {kFLOAT, kHALF}.</a>
<a name="142"><span class="lineNum">     142 </span>            :     //! kUINT8 to {kFLOAT, kHALF} conversion will convert the integer values</a>
<a name="143"><span class="lineNum">     143 </span>            :     //! to equivalent floating point values.</a>
<a name="144"><span class="lineNum">     144 </span>            :     //! {kFLOAT, kHALF} to kUINT8 conversion will convert the floating point values</a>
<a name="145"><span class="lineNum">     145 </span>            :     //! to integer values by truncating towards zero. This conversion has undefined behavior for</a>
<a name="146"><span class="lineNum">     146 </span>            :     //! floating point values outside the range [0.0f, 256.0f) after truncation.</a>
<a name="147"><span class="lineNum">     147 </span>            :     //! kUINT8 conversions are not supported for {kINT8, kINT32, kBOOL}.</a>
<a name="148"><span class="lineNum">     148 </span>            :     kUINT8 = 5,</a>
<a name="149"><span class="lineNum">     149 </span>            : </a>
<a name="150"><span class="lineNum">     150 </span>            :     //! Signed 8-bit floating point with</a>
<a name="151"><span class="lineNum">     151 </span>            :     //! 1 sign bit, 4 exponent bits, 3 mantissa bits, and exponent-bias 7.</a>
<a name="152"><span class="lineNum">     152 </span>            :     //! \warning kFP8 is not supported yet and will result in an error or undefined behavior.</a>
<a name="153"><span class="lineNum">     153 </span>            :     kFP8 = 6</a>
<a name="154"><span class="lineNum">     154 </span>            : </a>
<a name="155"><span class="lineNum">     155 </span>            : };</a>
<a name="156"><span class="lineNum">     156 </span>            : </a>
<a name="157"><span class="lineNum">     157 </span>            : namespace impl</a>
<a name="158"><span class="lineNum">     158 </span>            : {</a>
<a name="159"><span class="lineNum">     159 </span>            : //! Maximum number of elements in DataType enum. \see DataType</a>
<a name="160"><span class="lineNum">     160 </span>            : template &lt;&gt;</a>
<a name="161"><span class="lineNum">     161 </span>            : struct EnumMaxImpl&lt;DataType&gt;</a>
<a name="162"><span class="lineNum">     162 </span>            : {</a>
<a name="163"><span class="lineNum">     163 </span>            :     // Declaration of kVALUE that represents maximum number of elements in DataType enum</a>
<a name="164"><span class="lineNum">     164 </span>            :     static constexpr int32_t kVALUE = 7;</a>
<a name="165"><span class="lineNum">     165 </span>            : };</a>
<a name="166"><span class="lineNum">     166 </span>            : } // namespace impl</a>
<a name="167"><span class="lineNum">     167 </span>            : </a>
<a name="168"><span class="lineNum">     168 </span>            : //!</a>
<a name="169"><span class="lineNum">     169 </span>            : //! \class Dims</a>
<a name="170"><span class="lineNum">     170 </span>            : //! \brief Structure to define the dimensions of a tensor.</a>
<a name="171"><span class="lineNum">     171 </span>            : //!</a>
<a name="172"><span class="lineNum">     172 </span>            : //! TensorRT can also return an invalid dims structure. This structure is represented by nbDims == -1</a>
<a name="173"><span class="lineNum">     173 </span>            : //! and d[i] == 0 for all d.</a>
<a name="174"><span class="lineNum">     174 </span>            : //!</a>
<a name="175"><span class="lineNum">     175 </span>            : //! TensorRT can also return an &quot;unknown rank&quot; dims structure. This structure is represented by nbDims == -1</a>
<a name="176"><span class="lineNum">     176 </span>            : //! and d[i] == -1 for all d.</a>
<a name="177"><span class="lineNum">     177 </span>            : //!</a>
<a name="178"><span class="lineNum">     178 </span>            : class Dims32</a>
<a name="179"><span class="lineNum">     179 </span>            : {</a>
<a name="180"><span class="lineNum">     180 </span>            : public:</a>
<a name="181"><span class="lineNum">     181 </span>            :     //! The maximum rank (number of dimensions) supported for a tensor.</a>
<a name="182"><span class="lineNum">     182 </span>            :     static constexpr int32_t MAX_DIMS{8};</a>
<a name="183"><span class="lineNum">     183 </span>            :     //! The rank (number of dimensions).</a>
<a name="184"><span class="lineNum">     184 </span>            :     int32_t nbDims;</a>
<a name="185"><span class="lineNum">     185 </span>            :     //! The extent of each dimension.</a>
<a name="186"><span class="lineNum">     186 </span>            :     int32_t d[MAX_DIMS];</a>
<a name="187"><span class="lineNum">     187 </span>            : };</a>
<a name="188"><span class="lineNum">     188 </span>            : </a>
<a name="189"><span class="lineNum">     189 </span>            : //!</a>
<a name="190"><span class="lineNum">     190 </span>            : //! Alias for Dims32.</a>
<a name="191"><span class="lineNum">     191 </span>            : //!</a>
<a name="192"><span class="lineNum">     192 </span>            : //! \warning: This alias might change in the future.</a>
<a name="193"><span class="lineNum">     193 </span>            : //!</a>
<a name="194"><span class="lineNum">     194 </span>            : using Dims = Dims32;</a>
<a name="195"><span class="lineNum">     195 </span>            : </a>
<a name="196"><span class="lineNum">     196 </span>            : //!</a>
<a name="197"><span class="lineNum">     197 </span>            : //! \enum TensorFormat</a>
<a name="198"><span class="lineNum">     198 </span>            : //!</a>
<a name="199"><span class="lineNum">     199 </span>            : //! \brief Format of the input/output tensors.</a>
<a name="200"><span class="lineNum">     200 </span>            : //!</a>
<a name="201"><span class="lineNum">     201 </span>            : //! This enum is used by both plugins and network I/O tensors.</a>
<a name="202"><span class="lineNum">     202 </span>            : //!</a>
<a name="203"><span class="lineNum">     203 </span>            : //! \see IPluginV2::supportsFormat(), safe::ICudaEngine::getBindingFormat()</a>
<a name="204"><span class="lineNum">     204 </span>            : //!</a>
<a name="205"><span class="lineNum">     205 </span>            : //! For more information about data formats, see the topic &quot;Data Format Description&quot; located in the</a>
<a name="206"><span class="lineNum">     206 </span>            : //! TensorRT Developer Guide.</a>
<a name="207"><span class="lineNum">     207 </span>            : //!</a>
<a name="208"><span class="lineNum">     208 </span>            : enum class TensorFormat : int32_t</a>
<a name="209"><span class="lineNum">     209 </span>            : {</a>
<a name="210"><span class="lineNum">     210 </span>            :     //! Row major linear format.</a>
<a name="211"><span class="lineNum">     211 </span>            :     //! For a tensor with dimensions {N, C, H, W} or {numbers, channels,</a>
<a name="212"><span class="lineNum">     212 </span>            :     //! columns, rows}, the dimensional index corresponds to {3, 2, 1, 0}</a>
<a name="213"><span class="lineNum">     213 </span>            :     //! and thus the order is W minor.</a>
<a name="214"><span class="lineNum">     214 </span>            :     //!</a>
<a name="215"><span class="lineNum">     215 </span>            :     //! For DLA usage, the tensor sizes are limited to C,H,W in the range [1,8192].</a>
<a name="216"><span class="lineNum">     216 </span>            :     //!</a>
<a name="217"><span class="lineNum">     217 </span>            :     kLINEAR = 0,</a>
<a name="218"><span class="lineNum">     218 </span>            : </a>
<a name="219"><span class="lineNum">     219 </span>            :     //! Two wide channel vectorized row major format. This format is bound to</a>
<a name="220"><span class="lineNum">     220 </span>            :     //! FP16. It is only available for dimensions &gt;= 3.</a>
<a name="221"><span class="lineNum">     221 </span>            :     //! For a tensor with dimensions {N, C, H, W},</a>
<a name="222"><span class="lineNum">     222 </span>            :     //! the memory layout is equivalent to a C array with dimensions</a>
<a name="223"><span class="lineNum">     223 </span>            :     //! [N][(C+1)/2][H][W][2], with the tensor coordinates (n, c, h, w)</a>
<a name="224"><span class="lineNum">     224 </span>            :     //! mapping to array subscript [n][c/2][h][w][c%2].</a>
<a name="225"><span class="lineNum">     225 </span>            :     kCHW2 = 1,</a>
<a name="226"><span class="lineNum">     226 </span>            : </a>
<a name="227"><span class="lineNum">     227 </span>            :     //! Eight channel format where C is padded to a multiple of 8. This format</a>
<a name="228"><span class="lineNum">     228 </span>            :     //! is bound to FP16. It is only available for dimensions &gt;= 3.</a>
<a name="229"><span class="lineNum">     229 </span>            :     //! For a tensor with dimensions {N, C, H, W},</a>
<a name="230"><span class="lineNum">     230 </span>            :     //! the memory layout is equivalent to the array with dimensions</a>
<a name="231"><span class="lineNum">     231 </span>            :     //! [N][H][W][(C+7)/8*8], with the tensor coordinates (n, c, h, w)</a>
<a name="232"><span class="lineNum">     232 </span>            :     //! mapping to array subscript [n][h][w][c].</a>
<a name="233"><span class="lineNum">     233 </span>            :     kHWC8 = 2,</a>
<a name="234"><span class="lineNum">     234 </span>            : </a>
<a name="235"><span class="lineNum">     235 </span>            :     //! Four wide channel vectorized row major format. This format is bound to</a>
<a name="236"><span class="lineNum">     236 </span>            :     //! INT8 or FP16. It is only available for dimensions &gt;= 3.</a>
<a name="237"><span class="lineNum">     237 </span>            :     //! For INT8, the C dimension must be a build-time constant.</a>
<a name="238"><span class="lineNum">     238 </span>            :     //! For a tensor with dimensions {N, C, H, W},</a>
<a name="239"><span class="lineNum">     239 </span>            :     //! the memory layout is equivalent to a C array with dimensions</a>
<a name="240"><span class="lineNum">     240 </span>            :     //! [N][(C+3)/4][H][W][4], with the tensor coordinates (n, c, h, w)</a>
<a name="241"><span class="lineNum">     241 </span>            :     //! mapping to array subscript [n][c/4][h][w][c%4].</a>
<a name="242"><span class="lineNum">     242 </span>            :     //!</a>
<a name="243"><span class="lineNum">     243 </span>            :     //! Deprecated usage:</a>
<a name="244"><span class="lineNum">     244 </span>            :     //!</a>
<a name="245"><span class="lineNum">     245 </span>            :     //! If running on the DLA, this format can be used for acceleration</a>
<a name="246"><span class="lineNum">     246 </span>            :     //! with the caveat that C must be equal or lesser than 4.</a>
<a name="247"><span class="lineNum">     247 </span>            :     //! If used as DLA input and the build option kGPU_FALLBACK is not specified,</a>
<a name="248"><span class="lineNum">     248 </span>            :     //! it needs to meet line stride requirement of DLA format. Column stride in bytes should</a>
<a name="249"><span class="lineNum">     249 </span>            :     //! be a multiple of 32 on Xavier and 64 on Orin.</a>
<a name="250"><span class="lineNum">     250 </span>            :     kCHW4 = 3,</a>
<a name="251"><span class="lineNum">     251 </span>            : </a>
<a name="252"><span class="lineNum">     252 </span>            :     //! Sixteen wide channel vectorized row major format. This format is bound</a>
<a name="253"><span class="lineNum">     253 </span>            :     //! to FP16. It is only available for dimensions &gt;= 3.</a>
<a name="254"><span class="lineNum">     254 </span>            :     //! For a tensor with dimensions {N, C, H, W},</a>
<a name="255"><span class="lineNum">     255 </span>            :     //! the memory layout is equivalent to a C array with dimensions</a>
<a name="256"><span class="lineNum">     256 </span>            :     //! [N][(C+15)/16][H][W][16], with the tensor coordinates (n, c, h, w)</a>
<a name="257"><span class="lineNum">     257 </span>            :     //! mapping to array subscript [n][c/16][h][w][c%16].</a>
<a name="258"><span class="lineNum">     258 </span>            :     //!</a>
<a name="259"><span class="lineNum">     259 </span>            :     //! For DLA usage, this format maps to the native feature format for FP16,</a>
<a name="260"><span class="lineNum">     260 </span>            :     //! and the tensor sizes are limited to C,H,W in the range [1,8192].</a>
<a name="261"><span class="lineNum">     261 </span>            :     //!</a>
<a name="262"><span class="lineNum">     262 </span>            :     kCHW16 = 4,</a>
<a name="263"><span class="lineNum">     263 </span>            : </a>
<a name="264"><span class="lineNum">     264 </span>            :     //! Thirty-two wide channel vectorized row major format. This format is</a>
<a name="265"><span class="lineNum">     265 </span>            :     //! only available for dimensions &gt;= 3.</a>
<a name="266"><span class="lineNum">     266 </span>            :     //! For a tensor with dimensions {N, C, H, W},</a>
<a name="267"><span class="lineNum">     267 </span>            :     //! the memory layout is equivalent to a C array with dimensions</a>
<a name="268"><span class="lineNum">     268 </span>            :     //! [N][(C+31)/32][H][W][32], with the tensor coordinates (n, c, h, w)</a>
<a name="269"><span class="lineNum">     269 </span>            :     //! mapping to array subscript [n][c/32][h][w][c%32].</a>
<a name="270"><span class="lineNum">     270 </span>            :     //!</a>
<a name="271"><span class="lineNum">     271 </span>            :     //! For DLA usage, this format maps to the native feature format for INT8,</a>
<a name="272"><span class="lineNum">     272 </span>            :     //! and the tensor sizes are limited to C,H,W in the range [1,8192].</a>
<a name="273"><span class="lineNum">     273 </span>            :     kCHW32 = 5,</a>
<a name="274"><span class="lineNum">     274 </span>            : </a>
<a name="275"><span class="lineNum">     275 </span>            :     //! Eight channel format where C is padded to a multiple of 8. This format</a>
<a name="276"><span class="lineNum">     276 </span>            :     //! is bound to FP16, and it is only available for dimensions &gt;= 4.</a>
<a name="277"><span class="lineNum">     277 </span>            :     //! For a tensor with dimensions {N, C, D, H, W},</a>
<a name="278"><span class="lineNum">     278 </span>            :     //! the memory layout is equivalent to an array with dimensions</a>
<a name="279"><span class="lineNum">     279 </span>            :     //! [N][D][H][W][(C+7)/8*8], with the tensor coordinates (n, c, d, h, w)</a>
<a name="280"><span class="lineNum">     280 </span>            :     //! mapping to array subscript [n][d][h][w][c].</a>
<a name="281"><span class="lineNum">     281 </span>            :     kDHWC8 = 6,</a>
<a name="282"><span class="lineNum">     282 </span>            : </a>
<a name="283"><span class="lineNum">     283 </span>            :     //! Thirty-two wide channel vectorized row major format. This format is</a>
<a name="284"><span class="lineNum">     284 </span>            :     //! bound to FP16 and INT8 and is only available for dimensions &gt;= 4.</a>
<a name="285"><span class="lineNum">     285 </span>            :     //! For a tensor with dimensions {N, C, D, H, W},</a>
<a name="286"><span class="lineNum">     286 </span>            :     //! the memory layout is equivalent to a C array with dimensions</a>
<a name="287"><span class="lineNum">     287 </span>            :     //! [N][(C+31)/32][D][H][W][32], with the tensor coordinates (n, c, d, h, w)</a>
<a name="288"><span class="lineNum">     288 </span>            :     //! mapping to array subscript [n][c/32][d][h][w][c%32].</a>
<a name="289"><span class="lineNum">     289 </span>            :     kCDHW32 = 7,</a>
<a name="290"><span class="lineNum">     290 </span>            : </a>
<a name="291"><span class="lineNum">     291 </span>            :     //! Non-vectorized channel-last format. This format is bound to either FP32 or UINT8,</a>
<a name="292"><span class="lineNum">     292 </span>            :     //! and is only available for dimensions &gt;= 3.</a>
<a name="293"><span class="lineNum">     293 </span>            :     kHWC = 8,</a>
<a name="294"><span class="lineNum">     294 </span>            : </a>
<a name="295"><span class="lineNum">     295 </span>            :     //! DLA planar format. For a tensor with dimension {N, C, H, W}, the W axis</a>
<a name="296"><span class="lineNum">     296 </span>            :     //! always has unit stride. The stride for stepping along the H axis is</a>
<a name="297"><span class="lineNum">     297 </span>            :     //! rounded up to 64 bytes.</a>
<a name="298"><span class="lineNum">     298 </span>            :     //!</a>
<a name="299"><span class="lineNum">     299 </span>            :     //! The memory layout is equivalent to a C array with dimensions</a>
<a name="300"><span class="lineNum">     300 </span>            :     //! [N][C][H][roundUp(W, 64/elementSize)] where elementSize is</a>
<a name="301"><span class="lineNum">     301 </span>            :     //! 2 for FP16 and 1 for Int8, with the tensor coordinates (n, c, h, w)</a>
<a name="302"><span class="lineNum">     302 </span>            :     //! mapping to array subscript [n][c][h][w].</a>
<a name="303"><span class="lineNum">     303 </span>            :     kDLA_LINEAR = 9,</a>
<a name="304"><span class="lineNum">     304 </span>            : </a>
<a name="305"><span class="lineNum">     305 </span>            :     //! DLA image format. For a tensor with dimension {N, C, H, W} the C axis</a>
<a name="306"><span class="lineNum">     306 </span>            :     //! always has unit stride. The stride for stepping along the H axis is rounded up</a>
<a name="307"><span class="lineNum">     307 </span>            :     //! to 32 bytes on Xavier and 64 bytes on Orin. C can only be 1, 3 or 4.</a>
<a name="308"><span class="lineNum">     308 </span>            :     //! If C == 1, it will map to grayscale format.</a>
<a name="309"><span class="lineNum">     309 </span>            :     //! If C == 3 or C == 4, it will map to color image format. And if C == 3,</a>
<a name="310"><span class="lineNum">     310 </span>            :     //! the stride for stepping along the W axis needs to be padded to 4 in elements.</a>
<a name="311"><span class="lineNum">     311 </span>            :     //!</a>
<a name="312"><span class="lineNum">     312 </span>            :     //! When C is {1, 3, 4}, then C' is {1, 4, 4} respectively,</a>
<a name="313"><span class="lineNum">     313 </span>            :     //! the memory layout is equivalent to a C array with dimensions</a>
<a name="314"><span class="lineNum">     314 </span>            :     //! [N][H][roundUp(W, 32/C'/elementSize)][C'] on Xavier and [N][H][roundUp(W, 64/C'/elementSize)][C'] on Orin</a>
<a name="315"><span class="lineNum">     315 </span>            :     //! where elementSize is 2 for FP16</a>
<a name="316"><span class="lineNum">     316 </span>            :     //! and 1 for Int8. The tensor coordinates (n, c, h, w) mapping to array</a>
<a name="317"><span class="lineNum">     317 </span>            :     //! subscript [n][h][w][c].</a>
<a name="318"><span class="lineNum">     318 </span>            :     kDLA_HWC4 = 10,</a>
<a name="319"><span class="lineNum">     319 </span>            : </a>
<a name="320"><span class="lineNum">     320 </span>            :     //! Sixteen channel format where C is padded to a multiple of 16. This format</a>
<a name="321"><span class="lineNum">     321 </span>            :     //! is bound to FP16. It is only available for dimensions &gt;= 3.</a>
<a name="322"><span class="lineNum">     322 </span>            :     //! For a tensor with dimensions {N, C, H, W},</a>
<a name="323"><span class="lineNum">     323 </span>            :     //! the memory layout is equivalent to the array with dimensions</a>
<a name="324"><span class="lineNum">     324 </span>            :     //! [N][H][W][(C+15)/16*16], with the tensor coordinates (n, c, h, w)</a>
<a name="325"><span class="lineNum">     325 </span>            :     //! mapping to array subscript [n][h][w][c].</a>
<a name="326"><span class="lineNum">     326 </span>            :     kHWC16 = 11,</a>
<a name="327"><span class="lineNum">     327 </span>            : </a>
<a name="328"><span class="lineNum">     328 </span>            :     //! Non-vectorized channel-last format. This format is bound to FP32.</a>
<a name="329"><span class="lineNum">     329 </span>            :     //! It is only available for dimensions &gt;= 4.</a>
<a name="330"><span class="lineNum">     330 </span>            :     kDHWC = 12</a>
<a name="331"><span class="lineNum">     331 </span>            : };</a>
<a name="332"><span class="lineNum">     332 </span>            : </a>
<a name="333"><span class="lineNum">     333 </span>            : namespace impl</a>
<a name="334"><span class="lineNum">     334 </span>            : {</a>
<a name="335"><span class="lineNum">     335 </span>            : //! Maximum number of elements in TensorFormat enum. \see TensorFormat</a>
<a name="336"><span class="lineNum">     336 </span>            : template &lt;&gt;</a>
<a name="337"><span class="lineNum">     337 </span>            : struct EnumMaxImpl&lt;TensorFormat&gt;</a>
<a name="338"><span class="lineNum">     338 </span>            : {</a>
<a name="339"><span class="lineNum">     339 </span>            :     //! Declaration of kVALUE that represents maximum number of elements in TensorFormat enum</a>
<a name="340"><span class="lineNum">     340 </span>            :     static constexpr int32_t kVALUE = 13;</a>
<a name="341"><span class="lineNum">     341 </span>            : };</a>
<a name="342"><span class="lineNum">     342 </span>            : } // namespace impl</a>
<a name="343"><span class="lineNum">     343 </span>            : </a>
<a name="344"><span class="lineNum">     344 </span>            : enum class AllocatorFlag : int32_t</a>
<a name="345"><span class="lineNum">     345 </span>            : {</a>
<a name="346"><span class="lineNum">     346 </span>            :     kRESIZABLE = 0, //!&lt; TensorRT may call realloc() on this allocation</a>
<a name="347"><span class="lineNum">     347 </span>            : };</a>
<a name="348"><span class="lineNum">     348 </span>            : </a>
<a name="349"><span class="lineNum">     349 </span>            : namespace impl</a>
<a name="350"><span class="lineNum">     350 </span>            : {</a>
<a name="351"><span class="lineNum">     351 </span>            : //! Maximum number of elements in AllocatorFlag enum. \see AllocatorFlag</a>
<a name="352"><span class="lineNum">     352 </span>            : template &lt;&gt;</a>
<a name="353"><span class="lineNum">     353 </span>            : struct EnumMaxImpl&lt;AllocatorFlag&gt;</a>
<a name="354"><span class="lineNum">     354 </span>            : {</a>
<a name="355"><span class="lineNum">     355 </span>            :     static constexpr int32_t kVALUE = 1;        //!&lt; maximum number of elements in AllocatorFlag enum</a>
<a name="356"><span class="lineNum">     356 </span>            : };</a>
<a name="357"><span class="lineNum">     357 </span>            : } // namespace impl</a>
<a name="358"><span class="lineNum">     358 </span>            : </a>
<a name="359"><span class="lineNum">     359 </span>            : using AllocatorFlags = uint32_t;</a>
<a name="360"><span class="lineNum">     360 </span>            : </a>
<a name="361"><span class="lineNum">     361 </span>            : //!</a>
<a name="362"><span class="lineNum">     362 </span>            : //! \class IGpuAllocator</a>
<a name="363"><span class="lineNum">     363 </span>            : //!</a>
<a name="364"><span class="lineNum">     364 </span>            : //! \brief Application-implemented class for controlling allocation on the GPU.</a>
<a name="365"><span class="lineNum">     365 </span>            : //!</a>
<a name="366"><span class="lineNum">     366 </span>            : class IGpuAllocator</a>
<a name="367"><span class="lineNum">     367 </span>            : {</a>
<a name="368"><span class="lineNum">     368 </span>            : public:</a>
<a name="369"><span class="lineNum">     369 </span>            :     //!</a>
<a name="370"><span class="lineNum">     370 </span>            :     //! A thread-safe callback implemented by the application to handle acquisition of GPU memory.</a>
<a name="371"><span class="lineNum">     371 </span>            :     //!</a>
<a name="372"><span class="lineNum">     372 </span>            :     //! \param size The size of the memory required.</a>
<a name="373"><span class="lineNum">     373 </span>            :     //! \param alignment The required alignment of memory. Alignment will be zero</a>
<a name="374"><span class="lineNum">     374 </span>            :     //!        or a power of 2 not exceeding the alignment guaranteed by cudaMalloc.</a>
<a name="375"><span class="lineNum">     375 </span>            :     //!        Thus this allocator can be safely implemented with cudaMalloc/cudaFree.</a>
<a name="376"><span class="lineNum">     376 </span>            :     //!        An alignment value of zero indicates any alignment is acceptable.</a>
<a name="377"><span class="lineNum">     377 </span>            :     //! \param flags Reserved for future use. In the current release, 0 will be passed.</a>
<a name="378"><span class="lineNum">     378 </span>            :     //!</a>
<a name="379"><span class="lineNum">     379 </span>            :     //! If an allocation request of size 0 is made, nullptr should be returned.</a>
<a name="380"><span class="lineNum">     380 </span>            :     //!</a>
<a name="381"><span class="lineNum">     381 </span>            :     //! If an allocation request cannot be satisfied, nullptr should be returned.</a>
<a name="382"><span class="lineNum">     382 </span>            :     //!</a>
<a name="383"><span class="lineNum">     383 </span>            :     //! \note The implementation must guarantee thread safety for concurrent allocate/free/reallocate/deallocate</a>
<a name="384"><span class="lineNum">     384 </span>            :     //! requests.</a>
<a name="385"><span class="lineNum">     385 </span>            :     //!</a>
<a name="386"><span class="lineNum">     386 </span>            :     //! \usage</a>
<a name="387"><span class="lineNum">     387 </span>            :     //! - Allowed context for the API call</a>
<a name="388"><span class="lineNum">     388 </span>            :     //!   - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads.</a>
<a name="389"><span class="lineNum">     389 </span>            :     //!</a>
<a name="390"><span class="lineNum">     390 </span>            :     virtual void* allocate(uint64_t const size, uint64_t const alignment, AllocatorFlags const flags) noexcept = 0;</a>
<a name="391"><span class="lineNum">     391 </span>            : </a>
<a name="392"><span class="lineNum">     392 </span>            :     //!</a>
<a name="393"><span class="lineNum">     393 </span>            :     //! A thread-safe callback implemented by the application to handle release of GPU memory.</a>
<a name="394"><span class="lineNum">     394 </span>            :     //!</a>
<a name="395"><span class="lineNum">     395 </span>            :     //! TensorRT may pass a nullptr to this function if it was previously returned by allocate().</a>
<a name="396"><span class="lineNum">     396 </span>            :     //!</a>
<a name="397"><span class="lineNum">     397 </span>            :     //! \param memory The acquired memory.</a>
<a name="398"><span class="lineNum">     398 </span>            :     //!</a>
<a name="399"><span class="lineNum">     399 </span>            :     //! \note The implementation must guarantee thread safety for concurrent allocate/free/reallocate/deallocate</a>
<a name="400"><span class="lineNum">     400 </span>            :     //! requests.</a>
<a name="401"><span class="lineNum">     401 </span>            :     //!</a>
<a name="402"><span class="lineNum">     402 </span>            :     //! \see deallocate()</a>
<a name="403"><span class="lineNum">     403 </span>            :     //!</a>
<a name="404"><span class="lineNum">     404 </span>            :     //! \deprecated Deprecated in TensorRT 8.0. Superseded by deallocate.</a>
<a name="405"><span class="lineNum">     405 </span>            :     //!</a>
<a name="406"><span class="lineNum">     406 </span>            :     //! \usage</a>
<a name="407"><span class="lineNum">     407 </span>            :     //! - Allowed context for the API call</a>
<a name="408"><span class="lineNum">     408 </span>            :     //!   - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads.</a>
<a name="409"><span class="lineNum">     409 </span>            :     //!</a>
<a name="410"><span class="lineNum">     410 </span>            :     TRT_DEPRECATED virtual void free(void* const memory) noexcept = 0;</a>
<a name="411"><span class="lineNum">     411 </span>            : </a>
<a name="412"><span class="lineNum">     412 </span>            :     //!</a>
<a name="413"><span class="lineNum">     413 </span>            :     //! Destructor declared virtual as general good practice for a class with virtual methods.</a>
<a name="414"><span class="lineNum">     414 </span>            :     //! TensorRT never calls the destructor for an IGpuAllocator defined by the application.</a>
<a name="415"><span class="lineNum">     415 </span>            :     //!</a>
<a name="416"><span class="lineNum">     416 </span>            :     virtual ~IGpuAllocator() = default;</a>
<a name="417"><span class="lineNum">     417 </span>            :     IGpuAllocator() = default;</a>
<a name="418"><span class="lineNum">     418 </span>            : </a>
<a name="419"><span class="lineNum">     419 </span>            :     //!</a>
<a name="420"><span class="lineNum">     420 </span>            :     //! A thread-safe callback implemented by the application to resize an existing allocation.</a>
<a name="421"><span class="lineNum">     421 </span>            :     //!</a>
<a name="422"><span class="lineNum">     422 </span>            :     //! Only allocations which were allocated with AllocatorFlag::kRESIZABLE will be resized.</a>
<a name="423"><span class="lineNum">     423 </span>            :     //!</a>
<a name="424"><span class="lineNum">     424 </span>            :     //! Options are one of:</a>
<a name="425"><span class="lineNum">     425 </span>            :     //! * resize in place leaving min(oldSize, newSize) bytes unchanged and return the original address</a>
<a name="426"><span class="lineNum">     426 </span>            :     //! * move min(oldSize, newSize) bytes to a new location of sufficient size and return its address</a>
<a name="427"><span class="lineNum">     427 </span>            :     //! * return nullptr, to indicate that the request could not be fulfilled.</a>
<a name="428"><span class="lineNum">     428 </span>            :     //!</a>
<a name="429"><span class="lineNum">     429 </span>            :     //! If nullptr is returned, TensorRT will assume that resize() is not implemented, and that the</a>
<a name="430"><span class="lineNum">     430 </span>            :     //! allocation at baseAddr is still valid.</a>
<a name="431"><span class="lineNum">     431 </span>            :     //!</a>
<a name="432"><span class="lineNum">     432 </span>            :     //! This method is made available for use cases where delegating the resize</a>
<a name="433"><span class="lineNum">     433 </span>            :     //! strategy to the application provides an opportunity to improve memory management.</a>
<a name="434"><span class="lineNum">     434 </span>            :     //! One possible implementation is to allocate a large virtual device buffer and</a>
<a name="435"><span class="lineNum">     435 </span>            :     //! progressively commit physical memory with cuMemMap. CU_MEM_ALLOC_GRANULARITY_RECOMMENDED</a>
<a name="436"><span class="lineNum">     436 </span>            :     //! is suggested in this case.</a>
<a name="437"><span class="lineNum">     437 </span>            :     //!</a>
<a name="438"><span class="lineNum">     438 </span>            :     //! TensorRT may call realloc to increase the buffer by relatively small amounts.</a>
<a name="439"><span class="lineNum">     439 </span>            :     //!</a>
<a name="440"><span class="lineNum">     440 </span>            :     //! \param baseAddr the address of the original allocation.</a>
<a name="441"><span class="lineNum">     441 </span>            :     //! \param alignment The alignment used by the original allocation.</a>
<a name="442"><span class="lineNum">     442 </span>            :     //! \param newSize The new memory size required.</a>
<a name="443"><span class="lineNum">     443 </span>            :     //! \return the address of the reallocated memory</a>
<a name="444"><span class="lineNum">     444 </span>            :     //!</a>
<a name="445"><span class="lineNum">     445 </span>            :     //! \note The implementation must guarantee thread safety for concurrent allocate/free/reallocate/deallocate</a>
<a name="446"><span class="lineNum">     446 </span>            :     //! requests.</a>
<a name="447"><span class="lineNum">     447 </span>            :     //!</a>
<a name="448"><span class="lineNum">     448 </span>            :     //! \usage</a>
<a name="449"><span class="lineNum">     449 </span>            :     //! - Allowed context for the API call</a>
<a name="450"><span class="lineNum">     450 </span>            :     //!   - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads.</a>
<a name="451"><span class="lineNum">     451 </span>            :     //!</a>
<a name="452"><span class="lineNum">     452 </span>            :     virtual void* reallocate(void* /*baseAddr*/, uint64_t /*alignment*/, uint64_t /*newSize*/) noexcept</a>
<a name="453"><span class="lineNum">     453 </span>            :     {</a>
<a name="454"><span class="lineNum">     454 </span>            :         return nullptr;</a>
<a name="455"><span class="lineNum">     455 </span>            :     }</a>
<a name="456"><span class="lineNum">     456 </span>            : </a>
<a name="457"><span class="lineNum">     457 </span>            :     //!</a>
<a name="458"><span class="lineNum">     458 </span>            :     //! A thread-safe callback implemented by the application to handle release of GPU memory.</a>
<a name="459"><span class="lineNum">     459 </span>            :     //!</a>
<a name="460"><span class="lineNum">     460 </span>            :     //! TensorRT may pass a nullptr to this function if it was previously returned by allocate().</a>
<a name="461"><span class="lineNum">     461 </span>            :     //!</a>
<a name="462"><span class="lineNum">     462 </span>            :     //! \param memory The acquired memory.</a>
<a name="463"><span class="lineNum">     463 </span>            :     //! \return True if the acquired memory is released successfully.</a>
<a name="464"><span class="lineNum">     464 </span>            :     //!</a>
<a name="465"><span class="lineNum">     465 </span>            :     //! \note The implementation must guarantee thread safety for concurrent allocate/free/reallocate/deallocate</a>
<a name="466"><span class="lineNum">     466 </span>            :     //! requests.</a>
<a name="467"><span class="lineNum">     467 </span>            :     //!</a>
<a name="468"><span class="lineNum">     468 </span>            :     //! \note If user-implemented free() might hit an error condition, the user should override deallocate() as the</a>
<a name="469"><span class="lineNum">     469 </span>            :     //! primary implementation and override free() to call deallocate() for backwards compatibility.</a>
<a name="470"><span class="lineNum">     470 </span>            :     //!</a>
<a name="471"><span class="lineNum">     471 </span>            :     //! \see free()</a>
<a name="472"><span class="lineNum">     472 </span>            :     //!</a>
<a name="473"><span class="lineNum">     473 </span>            :     //! \usage</a>
<a name="474"><span class="lineNum">     474 </span>            :     //! - Allowed context for the API call</a>
<a name="475"><span class="lineNum">     475 </span>            :     //!   - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads.</a>
<a name="476"><span class="lineNum">     476 </span>            :     //!</a>
<a name="477"><span class="lineNum">     477 </span>            :     virtual bool deallocate(void* const memory) noexcept</a>
<a name="478"><span class="lineNum">     478 </span>            :     {</a>
<a name="479"><span class="lineNum">     479 </span>            :         this-&gt;free(memory);</a>
<a name="480"><span class="lineNum">     480 </span>            :         return true;</a>
<a name="481"><span class="lineNum">     481 </span>            :     }</a>
<a name="482"><span class="lineNum">     482 </span>            : </a>
<a name="483"><span class="lineNum">     483 </span>            : protected:</a>
<a name="484"><span class="lineNum">     484 </span>            : // @cond SuppressDoxyWarnings</a>
<a name="485"><span class="lineNum">     485 </span>            :     IGpuAllocator(IGpuAllocator const&amp;) = default;</a>
<a name="486"><span class="lineNum">     486 </span>            :     IGpuAllocator(IGpuAllocator&amp;&amp;) = default;</a>
<a name="487"><span class="lineNum">     487 </span>            :     IGpuAllocator&amp; operator=(IGpuAllocator const&amp;) &amp; = default;</a>
<a name="488"><span class="lineNum">     488 </span>            :     IGpuAllocator&amp; operator=(IGpuAllocator&amp;&amp;) &amp; = default;</a>
<a name="489"><span class="lineNum">     489 </span>            : // @endcond</a>
<a name="490"><span class="lineNum">     490 </span>            : };</a>
<a name="491"><span class="lineNum">     491 </span>            : </a>
<a name="492"><span class="lineNum">     492 </span>            : //!</a>
<a name="493"><span class="lineNum">     493 </span>            : //! \class ILogger</a>
<a name="494"><span class="lineNum">     494 </span>            : //!</a>
<a name="495"><span class="lineNum">     495 </span>            : //! \brief Application-implemented logging interface for the builder, refitter and runtime.</a>
<a name="496"><span class="lineNum">     496 </span>            : //!</a>
<a name="497"><span class="lineNum">     497 </span>            : //! The logger used to create an instance of IBuilder, IRuntime or IRefitter is used for all objects created through</a>
<a name="498"><span class="lineNum">     498 </span>            : //! that interface. The logger should be valid until all objects created are released.</a>
<a name="499"><span class="lineNum">     499 </span>            : //!</a>
<a name="500"><span class="lineNum">     500 </span>            : //! The Logger object implementation must be thread safe. All locking and synchronization is pushed to the</a>
<a name="501"><span class="lineNum">     501 </span>            : //! interface implementation and TensorRT does not hold any synchronization primitives when calling the interface</a>
<a name="502"><span class="lineNum">     502 </span>            : //! functions.</a>
<a name="503"><span class="lineNum">     503 </span>            : //!</a>
<a name="504"><span class="lineNum">     504 </span>            : class ILogger</a>
<a name="505"><span class="lineNum">     505 </span>            : {</a>
<a name="506"><span class="lineNum">     506 </span>            : public:</a>
<a name="507"><span class="lineNum">     507 </span>            :     //!</a>
<a name="508"><span class="lineNum">     508 </span>            :     //! \enum Severity</a>
<a name="509"><span class="lineNum">     509 </span>            :     //!</a>
<a name="510"><span class="lineNum">     510 </span>            :     //! The severity corresponding to a log message.</a>
<a name="511"><span class="lineNum">     511 </span>            :     //!</a>
<a name="512"><span class="lineNum">     512 </span>            :     enum class Severity : int32_t</a>
<a name="513"><span class="lineNum">     513 </span>            :     {</a>
<a name="514"><span class="lineNum">     514 </span>            :         //! An internal error has occurred. Execution is unrecoverable.</a>
<a name="515"><span class="lineNum">     515 </span>            :         kINTERNAL_ERROR = 0,</a>
<a name="516"><span class="lineNum">     516 </span>            :         //! An application error has occurred.</a>
<a name="517"><span class="lineNum">     517 </span>            :         kERROR = 1,</a>
<a name="518"><span class="lineNum">     518 </span>            :         //! An application error has been discovered, but TensorRT has recovered or fallen back to a default.</a>
<a name="519"><span class="lineNum">     519 </span>            :         kWARNING = 2,</a>
<a name="520"><span class="lineNum">     520 </span>            :         //!  Informational messages with instructional information.</a>
<a name="521"><span class="lineNum">     521 </span>            :         kINFO = 3,</a>
<a name="522"><span class="lineNum">     522 </span>            :         //!  Verbose messages with debugging information.</a>
<a name="523"><span class="lineNum">     523 </span>            :         kVERBOSE = 4,</a>
<a name="524"><span class="lineNum">     524 </span>            :     };</a>
<a name="525"><span class="lineNum">     525 </span>            : </a>
<a name="526"><span class="lineNum">     526 </span>            :     //!</a>
<a name="527"><span class="lineNum">     527 </span>            :     //! A callback implemented by the application to handle logging messages;</a>
<a name="528"><span class="lineNum">     528 </span>            :     //!</a>
<a name="529"><span class="lineNum">     529 </span>            :     //! \param severity The severity of the message.</a>
<a name="530"><span class="lineNum">     530 </span>            :     //! \param msg A null-terminated log message.</a>
<a name="531"><span class="lineNum">     531 </span>            :     //!</a>
<a name="532"><span class="lineNum">     532 </span>            :     //! \usage</a>
<a name="533"><span class="lineNum">     533 </span>            :     //! - Allowed context for the API call</a>
<a name="534"><span class="lineNum">     534 </span>            :     //!   - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads</a>
<a name="535"><span class="lineNum">     535 </span>            :     //!                  when multiple execution contexts are used during runtime, or if the same logger is used</a>
<a name="536"><span class="lineNum">     536 </span>            :     //!                  for multiple runtimes, builders, or refitters.</a>
<a name="537"><span class="lineNum">     537 </span>            :     //!</a>
<a name="538"><span class="lineNum">     538 </span>            :     virtual void log(Severity severity, AsciiChar const* msg) noexcept = 0;</a>
<a name="539"><span class="lineNum">     539 </span>            : </a>
<a name="540"><span class="lineNum">     540 </span>            :     ILogger() = default;</a>
<a name="541"><span class="lineNum">     541 </span><span class="lineNoCov">          0 :     virtual ~ILogger() = default;</span></a>
<a name="542"><span class="lineNum">     542 </span>            : </a>
<a name="543"><span class="lineNum">     543 </span>            : protected:</a>
<a name="544"><span class="lineNum">     544 </span>            : // @cond SuppressDoxyWarnings</a>
<a name="545"><span class="lineNum">     545 </span>            :     ILogger(ILogger const&amp;) = default;</a>
<a name="546"><span class="lineNum">     546 </span>            :     ILogger(ILogger&amp;&amp;) = default;</a>
<a name="547"><span class="lineNum">     547 </span>            :     ILogger&amp; operator=(ILogger const&amp;) &amp; = default;</a>
<a name="548"><span class="lineNum">     548 </span>            :     ILogger&amp; operator=(ILogger&amp;&amp;) &amp; = default;</a>
<a name="549"><span class="lineNum">     549 </span>            : // @endcond</a>
<a name="550"><span class="lineNum">     550 </span>            : };</a>
<a name="551"><span class="lineNum">     551 </span>            : </a>
<a name="552"><span class="lineNum">     552 </span>            : namespace impl</a>
<a name="553"><span class="lineNum">     553 </span>            : {</a>
<a name="554"><span class="lineNum">     554 </span>            : //! Maximum number of elements in ILogger::Severity enum. \see ILogger::Severity</a>
<a name="555"><span class="lineNum">     555 </span>            : template &lt;&gt;</a>
<a name="556"><span class="lineNum">     556 </span>            : struct EnumMaxImpl&lt;ILogger::Severity&gt;</a>
<a name="557"><span class="lineNum">     557 </span>            : {</a>
<a name="558"><span class="lineNum">     558 </span>            :     //! Declaration of kVALUE that represents maximum number of elements in ILogger::Severity enum</a>
<a name="559"><span class="lineNum">     559 </span>            :     static constexpr int32_t kVALUE = 5;</a>
<a name="560"><span class="lineNum">     560 </span>            : };</a>
<a name="561"><span class="lineNum">     561 </span>            : } // namespace impl</a>
<a name="562"><span class="lineNum">     562 </span>            : </a>
<a name="563"><span class="lineNum">     563 </span>            : //!</a>
<a name="564"><span class="lineNum">     564 </span>            : //! \enum ErrorCode</a>
<a name="565"><span class="lineNum">     565 </span>            : //!</a>
<a name="566"><span class="lineNum">     566 </span>            : //! \brief Error codes that can be returned by TensorRT during execution.</a>
<a name="567"><span class="lineNum">     567 </span>            : //!</a>
<a name="568"><span class="lineNum">     568 </span>            : enum class ErrorCode : int32_t</a>
<a name="569"><span class="lineNum">     569 </span>            : {</a>
<a name="570"><span class="lineNum">     570 </span>            :     //!</a>
<a name="571"><span class="lineNum">     571 </span>            :     //! Execution completed successfully.</a>
<a name="572"><span class="lineNum">     572 </span>            :     //!</a>
<a name="573"><span class="lineNum">     573 </span>            :     kSUCCESS = 0,</a>
<a name="574"><span class="lineNum">     574 </span>            : </a>
<a name="575"><span class="lineNum">     575 </span>            :     //!</a>
<a name="576"><span class="lineNum">     576 </span>            :     //! An error that does not fall into any other category. This error is included for forward compatibility.</a>
<a name="577"><span class="lineNum">     577 </span>            :     //!</a>
<a name="578"><span class="lineNum">     578 </span>            :     kUNSPECIFIED_ERROR = 1,</a>
<a name="579"><span class="lineNum">     579 </span>            : </a>
<a name="580"><span class="lineNum">     580 </span>            :     //!</a>
<a name="581"><span class="lineNum">     581 </span>            :     //! A non-recoverable TensorRT error occurred. TensorRT is in an invalid internal state when this error is</a>
<a name="582"><span class="lineNum">     582 </span>            :     //! emitted and any further calls to TensorRT will result in undefined behavior.</a>
<a name="583"><span class="lineNum">     583 </span>            :     //!</a>
<a name="584"><span class="lineNum">     584 </span>            :     kINTERNAL_ERROR = 2,</a>
<a name="585"><span class="lineNum">     585 </span>            : </a>
<a name="586"><span class="lineNum">     586 </span>            :     //!</a>
<a name="587"><span class="lineNum">     587 </span>            :     //! An argument passed to the function is invalid in isolation.</a>
<a name="588"><span class="lineNum">     588 </span>            :     //! This is a violation of the API contract.</a>
<a name="589"><span class="lineNum">     589 </span>            :     //!</a>
<a name="590"><span class="lineNum">     590 </span>            :     kINVALID_ARGUMENT = 3,</a>
<a name="591"><span class="lineNum">     591 </span>            : </a>
<a name="592"><span class="lineNum">     592 </span>            :     //!</a>
<a name="593"><span class="lineNum">     593 </span>            :     //! An error occurred when comparing the state of an argument relative to other arguments. For example, the</a>
<a name="594"><span class="lineNum">     594 </span>            :     //! dimensions for concat differ between two tensors outside of the channel dimension. This error is triggered</a>
<a name="595"><span class="lineNum">     595 </span>            :     //! when an argument is correct in isolation, but not relative to other arguments. This is to help to distinguish</a>
<a name="596"><span class="lineNum">     596 </span>            :     //! from the simple errors from the more complex errors.</a>
<a name="597"><span class="lineNum">     597 </span>            :     //! This is a violation of the API contract.</a>
<a name="598"><span class="lineNum">     598 </span>            :     //!</a>
<a name="599"><span class="lineNum">     599 </span>            :     kINVALID_CONFIG = 4,</a>
<a name="600"><span class="lineNum">     600 </span>            : </a>
<a name="601"><span class="lineNum">     601 </span>            :     //!</a>
<a name="602"><span class="lineNum">     602 </span>            :     //! An error occurred when performing an allocation of memory on the host or the device.</a>
<a name="603"><span class="lineNum">     603 </span>            :     //! A memory allocation error is normally fatal, but in the case where the application provided its own memory</a>
<a name="604"><span class="lineNum">     604 </span>            :     //! allocation routine, it is possible to increase the pool of available memory and resume execution.</a>
<a name="605"><span class="lineNum">     605 </span>            :     //!</a>
<a name="606"><span class="lineNum">     606 </span>            :     kFAILED_ALLOCATION = 5,</a>
<a name="607"><span class="lineNum">     607 </span>            : </a>
<a name="608"><span class="lineNum">     608 </span>            :     //!</a>
<a name="609"><span class="lineNum">     609 </span>            :     //! One, or more, of the components that TensorRT relies on did not initialize correctly.</a>
<a name="610"><span class="lineNum">     610 </span>            :     //! This is a system setup issue.</a>
<a name="611"><span class="lineNum">     611 </span>            :     //!</a>
<a name="612"><span class="lineNum">     612 </span>            :     kFAILED_INITIALIZATION = 6,</a>
<a name="613"><span class="lineNum">     613 </span>            : </a>
<a name="614"><span class="lineNum">     614 </span>            :     //!</a>
<a name="615"><span class="lineNum">     615 </span>            :     //! An error occurred during execution that caused TensorRT to end prematurely, either an asynchronous error or</a>
<a name="616"><span class="lineNum">     616 </span>            :     //! other execution errors reported by CUDA/DLA. In a dynamic system, the</a>
<a name="617"><span class="lineNum">     617 </span>            :     //! data can be thrown away and the next frame can be processed or execution can be retried.</a>
<a name="618"><span class="lineNum">     618 </span>            :     //! This is either an execution error or a memory error.</a>
<a name="619"><span class="lineNum">     619 </span>            :     //!</a>
<a name="620"><span class="lineNum">     620 </span>            :     kFAILED_EXECUTION = 7,</a>
<a name="621"><span class="lineNum">     621 </span>            : </a>
<a name="622"><span class="lineNum">     622 </span>            :     //!</a>
<a name="623"><span class="lineNum">     623 </span>            :     //! An error occurred during execution that caused the data to become corrupted, but execution finished. Examples</a>
<a name="624"><span class="lineNum">     624 </span>            :     //! of this error are NaN squashing or integer overflow. In a dynamic system, the data can be thrown away and the</a>
<a name="625"><span class="lineNum">     625 </span>            :     //! next frame can be processed or execution can be retried.</a>
<a name="626"><span class="lineNum">     626 </span>            :     //! This is either a data corruption error, an input error, or a range error.</a>
<a name="627"><span class="lineNum">     627 </span>            :     //! This is not used in safety but may be used in standard.</a>
<a name="628"><span class="lineNum">     628 </span>            :     //!</a>
<a name="629"><span class="lineNum">     629 </span>            :     kFAILED_COMPUTATION = 8,</a>
<a name="630"><span class="lineNum">     630 </span>            : </a>
<a name="631"><span class="lineNum">     631 </span>            :     //!</a>
<a name="632"><span class="lineNum">     632 </span>            :     //! TensorRT was put into a bad state by incorrect sequence of function calls. An example of an invalid state is</a>
<a name="633"><span class="lineNum">     633 </span>            :     //! specifying a layer to be DLA only without GPU fallback, and that layer is not supported by DLA. This can occur</a>
<a name="634"><span class="lineNum">     634 </span>            :     //! in situations where a service is optimistically executing networks for multiple different configurations</a>
<a name="635"><span class="lineNum">     635 </span>            :     //! without checking proper error configurations, and instead throwing away bad configurations caught by TensorRT.</a>
<a name="636"><span class="lineNum">     636 </span>            :     //! This is a violation of the API contract, but can be recoverable.</a>
<a name="637"><span class="lineNum">     637 </span>            :     //!</a>
<a name="638"><span class="lineNum">     638 </span>            :     //! Example of a recovery:</a>
<a name="639"><span class="lineNum">     639 </span>            :     //! GPU fallback is disabled and conv layer with large filter(63x63) is specified to run on DLA. This will fail due</a>
<a name="640"><span class="lineNum">     640 </span>            :     //! to DLA not supporting the large kernel size. This can be recovered by either turning on GPU fallback</a>
<a name="641"><span class="lineNum">     641 </span>            :     //! or setting the layer to run on the GPU.</a>
<a name="642"><span class="lineNum">     642 </span>            :     //!</a>
<a name="643"><span class="lineNum">     643 </span>            :     kINVALID_STATE = 9,</a>
<a name="644"><span class="lineNum">     644 </span>            : </a>
<a name="645"><span class="lineNum">     645 </span>            :     //!</a>
<a name="646"><span class="lineNum">     646 </span>            :     //! An error occurred due to the network not being supported on the device due to constraints of the hardware or</a>
<a name="647"><span class="lineNum">     647 </span>            :     //! system. An example is running a unsafe layer in a safety certified context, or a resource requirement for the</a>
<a name="648"><span class="lineNum">     648 </span>            :     //! current network is greater than the capabilities of the target device. The network is otherwise correct, but</a>
<a name="649"><span class="lineNum">     649 </span>            :     //! the network and hardware combination is problematic. This can be recoverable.</a>
<a name="650"><span class="lineNum">     650 </span>            :     //! Examples:</a>
<a name="651"><span class="lineNum">     651 </span>            :     //!  * Scratch space requests larger than available device memory and can be recovered by increasing allowed</a>
<a name="652"><span class="lineNum">     652 </span>            :     //!    workspace size.</a>
<a name="653"><span class="lineNum">     653 </span>            :     //!  * Tensor size exceeds the maximum element count and can be recovered by reducing the maximum batch size.</a>
<a name="654"><span class="lineNum">     654 </span>            :     //!</a>
<a name="655"><span class="lineNum">     655 </span>            :     kUNSUPPORTED_STATE = 10,</a>
<a name="656"><span class="lineNum">     656 </span>            : </a>
<a name="657"><span class="lineNum">     657 </span>            : };</a>
<a name="658"><span class="lineNum">     658 </span>            : </a>
<a name="659"><span class="lineNum">     659 </span>            : namespace impl</a>
<a name="660"><span class="lineNum">     660 </span>            : {</a>
<a name="661"><span class="lineNum">     661 </span>            : //! Maximum number of elements in ErrorCode enum. \see ErrorCode</a>
<a name="662"><span class="lineNum">     662 </span>            : template &lt;&gt;</a>
<a name="663"><span class="lineNum">     663 </span>            : struct EnumMaxImpl&lt;ErrorCode&gt;</a>
<a name="664"><span class="lineNum">     664 </span>            : {</a>
<a name="665"><span class="lineNum">     665 </span>            :     //! Declaration of kVALUE</a>
<a name="666"><span class="lineNum">     666 </span>            :     static constexpr int32_t kVALUE = 11;</a>
<a name="667"><span class="lineNum">     667 </span>            : };</a>
<a name="668"><span class="lineNum">     668 </span>            : } // namespace impl</a>
<a name="669"><span class="lineNum">     669 </span>            : </a>
<a name="670"><span class="lineNum">     670 </span>            : //!</a>
<a name="671"><span class="lineNum">     671 </span>            : //! \class IErrorRecorder</a>
<a name="672"><span class="lineNum">     672 </span>            : //!</a>
<a name="673"><span class="lineNum">     673 </span>            : //! \brief Reference counted application-implemented error reporting interface for TensorRT objects.</a>
<a name="674"><span class="lineNum">     674 </span>            : //!</a>
<a name="675"><span class="lineNum">     675 </span>            : //! The error reporting mechanism is a user defined object that interacts with the internal state of the object</a>
<a name="676"><span class="lineNum">     676 </span>            : //! that it is assigned to in order to determine information about abnormalities in execution. The error recorder</a>
<a name="677"><span class="lineNum">     677 </span>            : //! gets both an error enum that is more descriptive than pass/fail and also a string description that gives more</a>
<a name="678"><span class="lineNum">     678 </span>            : //! detail on the exact failure modes. In the safety context, the error strings are all limited to 1024 characters</a>
<a name="679"><span class="lineNum">     679 </span>            : //! in length.</a>
<a name="680"><span class="lineNum">     680 </span>            : //!</a>
<a name="681"><span class="lineNum">     681 </span>            : //! The ErrorRecorder gets passed along to any class that is created from another class that has an ErrorRecorder</a>
<a name="682"><span class="lineNum">     682 </span>            : //! assigned to it. For example, assigning an ErrorRecorder to an IBuilder allows all INetwork's, ILayer's, and</a>
<a name="683"><span class="lineNum">     683 </span>            : //! ITensor's to use the same error recorder. For functions that have their own ErrorRecorder accessor functions.</a>
<a name="684"><span class="lineNum">     684 </span>            : //! This allows registering a different error recorder or de-registering of the error recorder for that specific</a>
<a name="685"><span class="lineNum">     685 </span>            : //! object.</a>
<a name="686"><span class="lineNum">     686 </span>            : //!</a>
<a name="687"><span class="lineNum">     687 </span>            : //! The ErrorRecorder object implementation must be thread safe. All locking and synchronization is pushed to the</a>
<a name="688"><span class="lineNum">     688 </span>            : //! interface implementation and TensorRT does not hold any synchronization primitives when calling the interface</a>
<a name="689"><span class="lineNum">     689 </span>            : //! functions.</a>
<a name="690"><span class="lineNum">     690 </span>            : //!</a>
<a name="691"><span class="lineNum">     691 </span>            : //! The lifetime of the ErrorRecorder object must exceed the lifetime of all TensorRT objects that use it.</a>
<a name="692"><span class="lineNum">     692 </span>            : //!</a>
<a name="693"><span class="lineNum">     693 </span>            : class IErrorRecorder</a>
<a name="694"><span class="lineNum">     694 </span>            : {</a>
<a name="695"><span class="lineNum">     695 </span>            : public:</a>
<a name="696"><span class="lineNum">     696 </span>            :     //!</a>
<a name="697"><span class="lineNum">     697 </span>            :     //! A typedef of a C-style string for reporting error descriptions.</a>
<a name="698"><span class="lineNum">     698 </span>            :     //!</a>
<a name="699"><span class="lineNum">     699 </span>            :     using ErrorDesc = char const*;</a>
<a name="700"><span class="lineNum">     700 </span>            : </a>
<a name="701"><span class="lineNum">     701 </span>            :     //!</a>
<a name="702"><span class="lineNum">     702 </span>            :     //! The length limit for an error description, excluding the '\0' string terminator.</a>
<a name="703"><span class="lineNum">     703 </span>            :     //!</a>
<a name="704"><span class="lineNum">     704 </span>            :     static constexpr size_t kMAX_DESC_LENGTH{127U};</a>
<a name="705"><span class="lineNum">     705 </span>            : </a>
<a name="706"><span class="lineNum">     706 </span>            :     //!</a>
<a name="707"><span class="lineNum">     707 </span>            :     //! A typedef of a 32bit integer for reference counting.</a>
<a name="708"><span class="lineNum">     708 </span>            :     //!</a>
<a name="709"><span class="lineNum">     709 </span>            :     using RefCount = int32_t;</a>
<a name="710"><span class="lineNum">     710 </span>            : </a>
<a name="711"><span class="lineNum">     711 </span>            :     IErrorRecorder() = default;</a>
<a name="712"><span class="lineNum">     712 </span>            :     virtual ~IErrorRecorder() noexcept = default;</a>
<a name="713"><span class="lineNum">     713 </span>            : </a>
<a name="714"><span class="lineNum">     714 </span>            :     // Public API used to retrieve information from the error recorder.</a>
<a name="715"><span class="lineNum">     715 </span>            : </a>
<a name="716"><span class="lineNum">     716 </span>            :     //!</a>
<a name="717"><span class="lineNum">     717 </span>            :     //! \brief Return the number of errors</a>
<a name="718"><span class="lineNum">     718 </span>            :     //!</a>
<a name="719"><span class="lineNum">     719 </span>            :     //! Determines the number of errors that occurred between the current point in execution</a>
<a name="720"><span class="lineNum">     720 </span>            :     //! and the last time that the clear() was executed. Due to the possibility of asynchronous</a>
<a name="721"><span class="lineNum">     721 </span>            :     //! errors occuring, a TensorRT API can return correct results, but still register errors</a>
<a name="722"><span class="lineNum">     722 </span>            :     //! with the Error Recorder. The value of getNbErrors must monotonically increases until clear()</a>
<a name="723"><span class="lineNum">     723 </span>            :     //! is called.</a>
<a name="724"><span class="lineNum">     724 </span>            :     //!</a>
<a name="725"><span class="lineNum">     725 </span>            :     //! \return Returns the number of errors detected, or 0 if there are no errors.</a>
<a name="726"><span class="lineNum">     726 </span>            :     //!</a>
<a name="727"><span class="lineNum">     727 </span>            :     //! \see clear</a>
<a name="728"><span class="lineNum">     728 </span>            :     //!</a>
<a name="729"><span class="lineNum">     729 </span>            :     //! \usage</a>
<a name="730"><span class="lineNum">     730 </span>            :     //! - Allowed context for the API call</a>
<a name="731"><span class="lineNum">     731 </span>            :     //!   - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads</a>
<a name="732"><span class="lineNum">     732 </span>            :     //!                  when multiple execution contexts are used during runtime.</a>
<a name="733"><span class="lineNum">     733 </span>            :     //!</a>
<a name="734"><span class="lineNum">     734 </span>            :     virtual int32_t getNbErrors() const noexcept = 0;</a>
<a name="735"><span class="lineNum">     735 </span>            : </a>
<a name="736"><span class="lineNum">     736 </span>            :     //!</a>
<a name="737"><span class="lineNum">     737 </span>            :     //! \brief Returns the ErrorCode enumeration.</a>
<a name="738"><span class="lineNum">     738 </span>            :     //!</a>
<a name="739"><span class="lineNum">     739 </span>            :     //! \param errorIdx A 32-bit integer that indexes into the error array.</a>
<a name="740"><span class="lineNum">     740 </span>            :     //!</a>
<a name="741"><span class="lineNum">     741 </span>            :     //! The errorIdx specifies what error code from 0 to getNbErrors()-1 that the application</a>
<a name="742"><span class="lineNum">     742 </span>            :     //! wants to analyze and return the error code enum.</a>
<a name="743"><span class="lineNum">     743 </span>            :     //!</a>
<a name="744"><span class="lineNum">     744 </span>            :     //! \return Returns the enum corresponding to errorIdx.</a>
<a name="745"><span class="lineNum">     745 </span>            :     //!</a>
<a name="746"><span class="lineNum">     746 </span>            :     //! \see getErrorDesc, ErrorCode</a>
<a name="747"><span class="lineNum">     747 </span>            :     //!</a>
<a name="748"><span class="lineNum">     748 </span>            :     //! \usage</a>
<a name="749"><span class="lineNum">     749 </span>            :     //! - Allowed context for the API call</a>
<a name="750"><span class="lineNum">     750 </span>            :     //!   - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads</a>
<a name="751"><span class="lineNum">     751 </span>            :     //!                  when multiple execution contexts are used during runtime.</a>
<a name="752"><span class="lineNum">     752 </span>            :     //!</a>
<a name="753"><span class="lineNum">     753 </span>            :     virtual ErrorCode getErrorCode(int32_t errorIdx) const noexcept = 0;</a>
<a name="754"><span class="lineNum">     754 </span>            : </a>
<a name="755"><span class="lineNum">     755 </span>            :     //!</a>
<a name="756"><span class="lineNum">     756 </span>            :     //! \brief Returns a null-terminated C-style string description of the error.</a>
<a name="757"><span class="lineNum">     757 </span>            :     //!</a>
<a name="758"><span class="lineNum">     758 </span>            :     //! \param errorIdx A 32-bit integer that indexes into the error array.</a>
<a name="759"><span class="lineNum">     759 </span>            :     //!</a>
<a name="760"><span class="lineNum">     760 </span>            :     //! For the error specified by the idx value, return the string description of the error. The</a>
<a name="761"><span class="lineNum">     761 </span>            :     //! error string is a null-terminated C-style string. In the safety context there is a</a>
<a name="762"><span class="lineNum">     762 </span>            :     //! constant length requirement to remove any dynamic memory allocations and the error message</a>
<a name="763"><span class="lineNum">     763 </span>            :     //! may be truncated. The format of the string is &quot;&lt;EnumAsStr&gt; - &lt;Description&gt;&quot;.</a>
<a name="764"><span class="lineNum">     764 </span>            :     //!</a>
<a name="765"><span class="lineNum">     765 </span>            :     //! \return Returns a string representation of the error along with a description of the error.</a>
<a name="766"><span class="lineNum">     766 </span>            :     //!</a>
<a name="767"><span class="lineNum">     767 </span>            :     //! \see getErrorCode</a>
<a name="768"><span class="lineNum">     768 </span>            :     //!</a>
<a name="769"><span class="lineNum">     769 </span>            :     //! \usage</a>
<a name="770"><span class="lineNum">     770 </span>            :     //! - Allowed context for the API call</a>
<a name="771"><span class="lineNum">     771 </span>            :     //!   - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads</a>
<a name="772"><span class="lineNum">     772 </span>            :     //!                  when multiple execution contexts are used during runtime.</a>
<a name="773"><span class="lineNum">     773 </span>            :     //!</a>
<a name="774"><span class="lineNum">     774 </span>            :     virtual ErrorDesc getErrorDesc(int32_t errorIdx) const noexcept = 0;</a>
<a name="775"><span class="lineNum">     775 </span>            : </a>
<a name="776"><span class="lineNum">     776 </span>            :     //!</a>
<a name="777"><span class="lineNum">     777 </span>            :     //! \brief Determine if the error stack has overflowed.</a>
<a name="778"><span class="lineNum">     778 </span>            :     //!</a>
<a name="779"><span class="lineNum">     779 </span>            :     //! In the case when the number of errors is large, this function is used to query if one or more</a>
<a name="780"><span class="lineNum">     780 </span>            :     //! errors have been dropped due to lack of storage capacity. This is especially important in the</a>
<a name="781"><span class="lineNum">     781 </span>            :     //! automotive safety case where the internal error handling mechanisms cannot allocate memory.</a>
<a name="782"><span class="lineNum">     782 </span>            :     //!</a>
<a name="783"><span class="lineNum">     783 </span>            :     //! \return true if errors have been dropped due to overflowing the error stack.</a>
<a name="784"><span class="lineNum">     784 </span>            :     //!</a>
<a name="785"><span class="lineNum">     785 </span>            :     //! \usage</a>
<a name="786"><span class="lineNum">     786 </span>            :     //! - Allowed context for the API call</a>
<a name="787"><span class="lineNum">     787 </span>            :     //!   - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads</a>
<a name="788"><span class="lineNum">     788 </span>            :     //!                  when multiple execution contexts are used during runtime.</a>
<a name="789"><span class="lineNum">     789 </span>            :     //!</a>
<a name="790"><span class="lineNum">     790 </span>            :     virtual bool hasOverflowed() const noexcept = 0;</a>
<a name="791"><span class="lineNum">     791 </span>            : </a>
<a name="792"><span class="lineNum">     792 </span>            :     //!</a>
<a name="793"><span class="lineNum">     793 </span>            :     //! \brief Clear the error stack on the error recorder.</a>
<a name="794"><span class="lineNum">     794 </span>            :     //!</a>
<a name="795"><span class="lineNum">     795 </span>            :     //! Removes all the tracked errors by the error recorder.  This function must guarantee that after</a>
<a name="796"><span class="lineNum">     796 </span>            :     //! this function is called, and as long as no error occurs, the next call to getNbErrors will return</a>
<a name="797"><span class="lineNum">     797 </span>            :     //! zero.</a>
<a name="798"><span class="lineNum">     798 </span>            :     //!</a>
<a name="799"><span class="lineNum">     799 </span>            :     //! \see getNbErrors</a>
<a name="800"><span class="lineNum">     800 </span>            :     //!</a>
<a name="801"><span class="lineNum">     801 </span>            :     //! \usage</a>
<a name="802"><span class="lineNum">     802 </span>            :     //! - Allowed context for the API call</a>
<a name="803"><span class="lineNum">     803 </span>            :     //!   - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads</a>
<a name="804"><span class="lineNum">     804 </span>            :     //!                  when multiple execution contexts are used during runtime.</a>
<a name="805"><span class="lineNum">     805 </span>            :     //!</a>
<a name="806"><span class="lineNum">     806 </span>            :     virtual void clear() noexcept = 0;</a>
<a name="807"><span class="lineNum">     807 </span>            : </a>
<a name="808"><span class="lineNum">     808 </span>            :     // API used by TensorRT to report Error information to the application.</a>
<a name="809"><span class="lineNum">     809 </span>            : </a>
<a name="810"><span class="lineNum">     810 </span>            :     //!</a>
<a name="811"><span class="lineNum">     811 </span>            :     //! \brief Report an error to the error recorder with the corresponding enum and description.</a>
<a name="812"><span class="lineNum">     812 </span>            :     //!</a>
<a name="813"><span class="lineNum">     813 </span>            :     //! \param val The error code enum that is being reported.</a>
<a name="814"><span class="lineNum">     814 </span>            :     //! \param desc The string description of the error.</a>
<a name="815"><span class="lineNum">     815 </span>            :     //!</a>
<a name="816"><span class="lineNum">     816 </span>            :     //! Report an error to the user that has a given value and human readable description. The function returns false</a>
<a name="817"><span class="lineNum">     817 </span>            :     //! if processing can continue, which implies that the reported error is not fatal. This does not guarantee that</a>
<a name="818"><span class="lineNum">     818 </span>            :     //! processing continues, but provides a hint to TensorRT.</a>
<a name="819"><span class="lineNum">     819 </span>            :     //! The desc C-string data is only valid during the call to reportError and may be immediately deallocated by the</a>
<a name="820"><span class="lineNum">     820 </span>            :     //! caller when reportError returns. The implementation must not store the desc pointer in the ErrorRecorder object</a>
<a name="821"><span class="lineNum">     821 </span>            :     //! or otherwise access the data from desc after reportError returns.</a>
<a name="822"><span class="lineNum">     822 </span>            :     //!</a>
<a name="823"><span class="lineNum">     823 </span>            :     //! \return True if the error is determined to be fatal and processing of the current function must end.</a>
<a name="824"><span class="lineNum">     824 </span>            :     //!</a>
<a name="825"><span class="lineNum">     825 </span>            :     //! \usage</a>
<a name="826"><span class="lineNum">     826 </span>            :     //! - Allowed context for the API call</a>
<a name="827"><span class="lineNum">     827 </span>            :     //!   - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads</a>
<a name="828"><span class="lineNum">     828 </span>            :     //!                  when multiple execution contexts are used during runtime.</a>
<a name="829"><span class="lineNum">     829 </span>            :     //!</a>
<a name="830"><span class="lineNum">     830 </span>            :     virtual bool reportError(ErrorCode val, ErrorDesc desc) noexcept = 0;</a>
<a name="831"><span class="lineNum">     831 </span>            : </a>
<a name="832"><span class="lineNum">     832 </span>            :     //!</a>
<a name="833"><span class="lineNum">     833 </span>            :     //! \brief Increments the refcount for the current ErrorRecorder.</a>
<a name="834"><span class="lineNum">     834 </span>            :     //!</a>
<a name="835"><span class="lineNum">     835 </span>            :     //! Increments the reference count for the object by one and returns the current value.  This reference count allows</a>
<a name="836"><span class="lineNum">     836 </span>            :     //! the application to know that an object inside of TensorRT has taken a reference to the ErrorRecorder.  TensorRT</a>
<a name="837"><span class="lineNum">     837 </span>            :     //! guarantees that every call to IErrorRecorder::incRefCount will be paired with a call to</a>
<a name="838"><span class="lineNum">     838 </span>            :     //! IErrorRecorder::decRefCount when the reference is released.  It is undefined behavior to destruct the</a>
<a name="839"><span class="lineNum">     839 </span>            :     //! ErrorRecorder when incRefCount has been called without a corresponding decRefCount.</a>
<a name="840"><span class="lineNum">     840 </span>            :     //!</a>
<a name="841"><span class="lineNum">     841 </span>            :     //! \return The reference counted value after the increment completes.</a>
<a name="842"><span class="lineNum">     842 </span>            :     //!</a>
<a name="843"><span class="lineNum">     843 </span>            :     //! \usage</a>
<a name="844"><span class="lineNum">     844 </span>            :     //! - Allowed context for the API call</a>
<a name="845"><span class="lineNum">     845 </span>            :     //!   - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads</a>
<a name="846"><span class="lineNum">     846 </span>            :     //!                  when multiple execution contexts are used during runtime.</a>
<a name="847"><span class="lineNum">     847 </span>            :     //!</a>
<a name="848"><span class="lineNum">     848 </span>            :     virtual RefCount incRefCount() noexcept = 0;</a>
<a name="849"><span class="lineNum">     849 </span>            : </a>
<a name="850"><span class="lineNum">     850 </span>            :     //!</a>
<a name="851"><span class="lineNum">     851 </span>            :     //! \brief Decrements the refcount for the current ErrorRecorder.</a>
<a name="852"><span class="lineNum">     852 </span>            :     //!</a>
<a name="853"><span class="lineNum">     853 </span>            :     //! Decrements the reference count for the object by one and returns the current value.  This reference count allows</a>
<a name="854"><span class="lineNum">     854 </span>            :     //! the application to know that an object inside of TensorRT has taken a reference to the ErrorRecorder.  TensorRT</a>
<a name="855"><span class="lineNum">     855 </span>            :     //! guarantees that every call to IErrorRecorder::decRefCount will be preceded by a call to</a>
<a name="856"><span class="lineNum">     856 </span>            :     //! IErrorRecorder::incRefCount.  It is undefined behavior to destruct the ErrorRecorder when incRefCount has been</a>
<a name="857"><span class="lineNum">     857 </span>            :     //! called without a corresponding decRefCount.</a>
<a name="858"><span class="lineNum">     858 </span>            :     //!</a>
<a name="859"><span class="lineNum">     859 </span>            :     //! \return The reference counted value after the decrement completes.</a>
<a name="860"><span class="lineNum">     860 </span>            :     //!</a>
<a name="861"><span class="lineNum">     861 </span>            :     //! \usage</a>
<a name="862"><span class="lineNum">     862 </span>            :     //! - Allowed context for the API call</a>
<a name="863"><span class="lineNum">     863 </span>            :     //!   - Thread-safe: Yes, this method is required to be thread-safe and may be called from multiple threads</a>
<a name="864"><span class="lineNum">     864 </span>            :     //!                  when multiple execution contexts are used during runtime.</a>
<a name="865"><span class="lineNum">     865 </span>            :     //!</a>
<a name="866"><span class="lineNum">     866 </span>            :     virtual RefCount decRefCount() noexcept = 0;</a>
<a name="867"><span class="lineNum">     867 </span>            : </a>
<a name="868"><span class="lineNum">     868 </span>            : protected:</a>
<a name="869"><span class="lineNum">     869 </span>            :     // @cond SuppressDoxyWarnings</a>
<a name="870"><span class="lineNum">     870 </span>            :     IErrorRecorder(IErrorRecorder const&amp;) = default;</a>
<a name="871"><span class="lineNum">     871 </span>            :     IErrorRecorder(IErrorRecorder&amp;&amp;) = default;</a>
<a name="872"><span class="lineNum">     872 </span>            :     IErrorRecorder&amp; operator=(IErrorRecorder const&amp;) &amp; = default;</a>
<a name="873"><span class="lineNum">     873 </span>            :     IErrorRecorder&amp; operator=(IErrorRecorder&amp;&amp;) &amp; = default;</a>
<a name="874"><span class="lineNum">     874 </span>            :     // @endcond</a>
<a name="875"><span class="lineNum">     875 </span>            : }; // class IErrorRecorder</a>
<a name="876"><span class="lineNum">     876 </span>            : </a>
<a name="877"><span class="lineNum">     877 </span>            : //!</a>
<a name="878"><span class="lineNum">     878 </span>            : //! \enum TensorIOMode</a>
<a name="879"><span class="lineNum">     879 </span>            : //!</a>
<a name="880"><span class="lineNum">     880 </span>            : //! \brief Definition of tensor IO Mode.</a>
<a name="881"><span class="lineNum">     881 </span>            : //!</a>
<a name="882"><span class="lineNum">     882 </span>            : enum class TensorIOMode : int32_t</a>
<a name="883"><span class="lineNum">     883 </span>            : {</a>
<a name="884"><span class="lineNum">     884 </span>            :     //! Tensor is not an input or output.</a>
<a name="885"><span class="lineNum">     885 </span>            :     kNONE = 0,</a>
<a name="886"><span class="lineNum">     886 </span>            : </a>
<a name="887"><span class="lineNum">     887 </span>            :     //! Tensor is input to the engine.</a>
<a name="888"><span class="lineNum">     888 </span>            :     kINPUT = 1,</a>
<a name="889"><span class="lineNum">     889 </span>            : </a>
<a name="890"><span class="lineNum">     890 </span>            :     //! Tensor is output by the engine.</a>
<a name="891"><span class="lineNum">     891 </span>            :     kOUTPUT = 2</a>
<a name="892"><span class="lineNum">     892 </span>            : };</a>
<a name="893"><span class="lineNum">     893 </span>            : </a>
<a name="894"><span class="lineNum">     894 </span>            : namespace impl</a>
<a name="895"><span class="lineNum">     895 </span>            : {</a>
<a name="896"><span class="lineNum">     896 </span>            : //! Maximum number of elements in TensorIOMode enum. \see TensorIOMode</a>
<a name="897"><span class="lineNum">     897 </span>            : template &lt;&gt;</a>
<a name="898"><span class="lineNum">     898 </span>            : struct EnumMaxImpl&lt;TensorIOMode&gt;</a>
<a name="899"><span class="lineNum">     899 </span>            : {</a>
<a name="900"><span class="lineNum">     900 </span>            :     // Declaration of kVALUE that represents maximum number of elements in TensorIOMode enum</a>
<a name="901"><span class="lineNum">     901 </span>            :     static constexpr int32_t kVALUE = 3;</a>
<a name="902"><span class="lineNum">     902 </span>            : };</a>
<a name="903"><span class="lineNum">     903 </span>            : } // namespace impl</a>
<a name="904"><span class="lineNum">     904 </span>            : } // namespace nvinfer1</a>
<a name="905"><span class="lineNum">     905 </span>            : </a>
<a name="906"><span class="lineNum">     906 </span>            : //!</a>
<a name="907"><span class="lineNum">     907 </span>            : //! \brief Return the library version number.</a>
<a name="908"><span class="lineNum">     908 </span>            : //!</a>
<a name="909"><span class="lineNum">     909 </span>            : //! The format is as for TENSORRT_VERSION: (TENSORRT_MAJOR * 1000) + (TENSORRT_MINOR * 100) + TENSOR_PATCH.</a>
<a name="910"><span class="lineNum">     910 </span>            : //!</a>
<a name="911"><span class="lineNum">     911 </span>            : extern &quot;C&quot; TENSORRTAPI int32_t getInferLibVersion() noexcept;</a>
<a name="912"><span class="lineNum">     912 </span>            : </a>
<a name="913"><span class="lineNum">     913 </span>            : #endif // NV_INFER_RUNTIME_BASE_H</a>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.14</a></td></tr>
  </table>
  <br>

</body>
</html>
